{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2DeqM6VGH214"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#toDo1\n",
        "# Read and Observe the Dataset.\n",
        "data=pd.read_csv('student.csv')\n",
        "print(data)\n",
        "\n",
        "# Print top(5) and bottom(5) of the dataset\n",
        "print(data.head())\n",
        "print(data.tail())\n",
        "\n",
        "# Print the Information of Datasets.\n",
        "print(data.info())\n",
        "\n",
        "# Print the Descriptive info about the Dataset.\n",
        "print(data.describe())\n",
        "\n",
        "# Split your data into Feature (X) and Label (Y).\n",
        "# assume last column is label\n",
        "X=data.iloc[:,:-1]\n",
        "Y=data.iloc[:,-1]\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"Y shape:\", Y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o85NB1T3ICxa",
        "outputId": "758fb911-74d8-48f2-9dbb-bd0b875c7475"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Math  Reading  Writing\n",
            "0      48       68       63\n",
            "1      62       81       72\n",
            "2      79       80       78\n",
            "3      76       83       79\n",
            "4      59       64       62\n",
            "..    ...      ...      ...\n",
            "995    72       74       70\n",
            "996    73       86       90\n",
            "997    89       87       94\n",
            "998    83       82       78\n",
            "999    66       66       72\n",
            "\n",
            "[1000 rows x 3 columns]\n",
            "   Math  Reading  Writing\n",
            "0    48       68       63\n",
            "1    62       81       72\n",
            "2    79       80       78\n",
            "3    76       83       79\n",
            "4    59       64       62\n",
            "     Math  Reading  Writing\n",
            "995    72       74       70\n",
            "996    73       86       90\n",
            "997    89       87       94\n",
            "998    83       82       78\n",
            "999    66       66       72\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype\n",
            "---  ------   --------------  -----\n",
            " 0   Math     1000 non-null   int64\n",
            " 1   Reading  1000 non-null   int64\n",
            " 2   Writing  1000 non-null   int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 23.6 KB\n",
            "None\n",
            "              Math      Reading      Writing\n",
            "count  1000.000000  1000.000000  1000.000000\n",
            "mean     67.290000    69.872000    68.616000\n",
            "std      15.085008    14.657027    15.241287\n",
            "min      13.000000    19.000000    14.000000\n",
            "25%      58.000000    60.750000    58.000000\n",
            "50%      68.000000    70.000000    69.500000\n",
            "75%      78.000000    81.000000    79.000000\n",
            "max     100.000000   100.000000   100.000000\n",
            "X shape: (1000, 2)\n",
            "Y shape: (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#toDo-3\n",
        "'''Split the dataset into training and test sets.\n",
        "You can use an 80-20 or 70-30 split, with 80% (or 70%) of the data used for training and the rest\n",
        "for testing.'''\n",
        "\n",
        "# Function to split data into training and testing sets\n",
        "def train_test_split(X, y, test_size=0.3, random_state=42):\n",
        "\n",
        "    # Fix the random seed so results are same every time\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    # Create index numbers for all rows\n",
        "    indices = np.arange(X.shape[0])\n",
        "\n",
        "    # Shuffle the index numbers randomly\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    # Find how many samples go into test set\n",
        "    test_size_count = int(len(X) * test_size)\n",
        "\n",
        "    # First part → test data, remaining → training data\n",
        "    test_indices = indices[:test_size_count]\n",
        "    train_indices = indices[test_size_count:]\n",
        "\n",
        "    # Split features using indices\n",
        "    X_train = X[train_indices]\n",
        "    X_test = X[test_indices]\n",
        "\n",
        "    # Split labels using indices\n",
        "    y_train = y[train_indices]\n",
        "    y_test = y[test_indices]\n",
        "\n",
        "    # Return training and testing data\n",
        "    return X_train, X_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "_GxU5Q6rIV3c"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step -2- Build a Cost Function:\n",
        "def cost_function(X, Y, W):\n",
        "\n",
        "  \"\"\" Parameters:\n",
        "  This function finds the Mean Square Error.\n",
        "  Input parameters:\n",
        "  X: Feature Matrix\n",
        "  Y: Target Matrix\n",
        "  W: Weight Matrix\n",
        "  Output Parameters:\n",
        "  cost: accumulated mean square error.\n",
        "  \"\"\"\n",
        "  n = Y.shape[0]            # Number of data points\n",
        "\n",
        "  # Predict output using y_pred = X @ W Matrix Multiplication\n",
        "  y_pred = X @ W            # Shape: (n_samples,) 1D\n",
        "\n",
        "  # Calculate error (difference between predicted and actual)\n",
        "  error = y_pred - Y\n",
        "\n",
        "  # Calculate Mean Squared Error cost: L(W) = 1/(2n) * sum((y_pred - Y)^2)\n",
        "  cost = np.sum(error**2) / (2 * n)\n",
        "\n",
        "  return cost"
      ],
      "metadata": {
        "id": "QahbFyHBNkcF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, Y, W, alpha, iterations):\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  Perform gradient descent to optimize the parameters of a linear regression model.\n",
        "  Parameters:\n",
        "  X (numpy.ndarray): Feature matrix (m x n).\n",
        "  Y (numpy.ndarray): Target vector (m x 1).\n",
        "  W (numpy.ndarray): Initial guess for parameters (n x 1).\n",
        "  alpha (float): Learning rate.\n",
        "  iterations (int): Number of iterations for gradient descent.\n",
        "  Returns tuple: A tuple containing the final optimized parameters (W_update) and the history of cost values.\n",
        "  W_update (numpy.ndarray): Updated parameters (n x 1).\n",
        "  cost_history (list): History of cost values over iterations.\n",
        "  \"\"\"\n",
        "  # Initialize cost history\n",
        "  cost_history = [0] * iterations\n",
        "  # Number of samples\n",
        "  m = len(Y)\n",
        "  W_update = W.copy()\n",
        "  for iteration in range(iterations):\n",
        "    # Step 1: Hypothesis Values\n",
        "    Y_pred = X @ W_update\n",
        "\n",
        "    # Step 2: Difference between Hypothesis and Actual Y\n",
        "    loss = Y_pred - Y\n",
        "\n",
        "    # Step 3: Gradient Calculation\n",
        "    dw = (1/m) * X.T.dot(loss)\n",
        "\n",
        "    # Step 4: Updating Values of W using Gradient\n",
        "    W_update = W_update - alpha * dw\n",
        "\n",
        "    # Step 5: New Cost Value\n",
        "    cost = cost_function(X, Y, W_update)\n",
        "    cost_history[iteration] = cost\n",
        "  return W_update, cost_history\n",
        "\n"
      ],
      "metadata": {
        "id": "FFKfwV22RR_k"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation - RMSE\n",
        "def rmse(Y, Y_pred):\n",
        "  \"\"\"\n",
        "  This Function calculates the Root Mean Squres.\n",
        "  Input Arguments:\n",
        "  Y: Array of actual(Target) Dependent Varaibles.\n",
        "  Y_pred: Array of predeicted Dependent Varaibles.\n",
        "  Output Arguments:\n",
        "  rmse: Root Mean Square.\n",
        "  \"\"\"\n",
        "  loss = (Y - Y_pred)**2\n",
        "  rmse = np.sqrt(1/len(Y)*sum(loss))\n",
        "  return rmse"
      ],
      "metadata": {
        "id": "0f77m7dRWi2e"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation - R2\n",
        "def r2(Y, Y_pred):\n",
        "  \"\"\"\n",
        "  This Function calculates the R Squared Error.\n",
        "  Input Arguments:\n",
        "  Y: Array of actual(Target) Dependent Varaibles.\n",
        "  Y_pred: Array of predeicted Dependent Varaibles.\n",
        "  Output Arguments:\n",
        "  rsquared: R Squared Error.\n",
        "  \"\"\"\n",
        "  mean_y = np.mean(Y)\n",
        "  ss_tot = (Y - mean_y)**2\n",
        "  ss_res = (Y - Y_pred)**2\n",
        "  r2 = 1 - sum(ss_res)/sum(ss_tot)\n",
        "  return r2"
      ],
      "metadata": {
        "id": "96bHVqSLX1SO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  # Step 1: Load the dataset\n",
        "  data = pd.read_csv('student.csv')\n",
        "\n",
        "  # Step 2: Split the data into features (X) and target (Y)\n",
        "  X = data[['Math', 'Reading']].values # Features: Math and Reading marks\n",
        "  Y = data['Writing'].values # Target: Writing marks\n",
        "\n",
        "  # Step 3: Split the data into training and test sets (80% train, 20% test)\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "  # Step 4: Initialize weights (W) to zeros, learning rate and number of iterations\n",
        "  W = np.zeros(X_train.shape[1]) # Initialize weights\n",
        "  alpha = 0.0001 # Learning rate\n",
        "  iterations = 1000 # Number of iterations for gradient descent\n",
        "\n",
        "  # Step 5: Perform Gradient Descent\n",
        "  W_optimal, cost_history = gradient_descent(X_train, Y_train, W, alpha, iterations)\n",
        "\n",
        "  # Step 6: Make predictions on the test set\n",
        "  Y_pred = np.dot(X_test, W_optimal)\n",
        "\n",
        "  # Step 7: Evaluate the model using RMSE and R-Squared\n",
        "  model_rmse = rmse(Y_test, Y_pred)\n",
        "  model_r2 = r2(Y_test, Y_pred)\n",
        "\n",
        "  # Step 8: Output the results\n",
        "  print(\"Final Weights:\", W_optimal)\n",
        "  print(\"Cost History (First 10 iterations):\", cost_history[:10])\n",
        "  print(\"RMSE on Test Set:\", model_rmse)\n",
        "  print(\"R-Squared on Test Set:\", model_r2)\n",
        "\n",
        "# Execute the main function\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjn5w1GgZc1N",
        "outputId": "af9ec92a-6c09-4981-ddaa-5d98474b58f4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Weights: [0.0894932  0.89504864]\n",
            "Cost History (First 10 iterations): [np.float64(17.813797177522098), np.float64(16.9831490248783), np.float64(16.925140245010397), np.float64(16.867870818076216), np.float64(16.811093513105355), np.float64(16.754804026075387), np.float64(16.69899816573971), np.float64(16.64367177688582), np.float64(16.588820740001896), np.float64(16.53444097097003)]\n",
            "RMSE on Test Set: 4.792607360540953\n",
            "R-Squared on Test Set: 0.908240340333986\n"
          ]
        }
      ]
    }
  ]
}